{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "reported-southeast",
   "metadata": {},
   "source": [
    "# Notebook voor het analyseren van woord frequenties\n",
    "\n",
    "Met dit notebook kunnen de volgende kolommen geanalyseerd worden\n",
    "- indruk\n",
    "- ontwikkelingen\n",
    "- redenen\n",
    "- meegeven\n",
    "\n",
    "De tekst kan als zijn geheel weggeschreven worden of er kan op type woord geselecteerd worden en frequenties geanalyseerd worden. Gebruik wordt gemaakt van de nltk library en spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords          \n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import nl_core_news_sm\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# readfile\n",
    "df = pd.read_excel('ledenenquete_over_heel_de_mens.xlsx', skiprows=2, names = ['Serienummer', 'SID', 'Submitted Time', 'Verwerkingstijd',\n",
    "       'Modified Time', 'Kladversie', 'IP-adres', 'UID', 'Gebruikersnaam',\n",
    "       'Naam', 'Email', 'Afdeling',\n",
    "       'indruk', #12\n",
    "       'ontwikkelingen', #13\n",
    "       'redenen', #14\n",
    "       'meegeven']) #15\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df_complete = df[df.Verwerkingstijd.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "with open('wordlist.txt') as f: # get dutch dictionary\n",
    "    s = f.read()\n",
    "    DUTCH = word_tokenize(s) \n",
    "\n",
    "nlp = nl_core_news_sm.load()    # set memory to high\n",
    "nlp.max_length = 1500000\n",
    "\n",
    "stemmer = SnowballStemmer('dutch') # set dutch stemmer\n",
    "stopwords_dutch = list(stopwords.words('dutch')) # set dutch stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def clean_line(line):\n",
    "    \"\"\" function to clean a line from tabs, enters, punctuations\"\"\"\n",
    "    line = str(line)\n",
    "    line = re.sub(r'[^\\w\\s.\\/-:\\']', '', line)\n",
    "    line = re.sub(r'[\\n\\t]','', line)\n",
    "    line = line.lower().strip()\n",
    "    if not line.endswith('.'):\n",
    "        line = line + '.' \n",
    "    #print('@@', line)\n",
    "    return line\n",
    "\n",
    "\n",
    "# spell checker\n",
    "def edit_distance(entry='validatrie', wordlist = DUTCH):\n",
    "    \"\"\" function that check the closest word to correct spellingserrors\"\"\"\n",
    "    output = [entry]\n",
    "    try:\n",
    "        if (len(entry) - 2) > 4:\n",
    "            # get first 4 letters of each word with v\n",
    "            v = [i for i in wordlist if i[0:5]==entry[0:5]]\n",
    "            distance = [((nltk.edit_distance(entry, a)), a) for a in v]\n",
    "            output = [sorted(distance)[0][1]]\n",
    "        return output[0]\n",
    "    except:\n",
    "        return entry\n",
    "    \n",
    "    \n",
    "def write_subject_to_file(df, subject, column, nr):\n",
    "    \"\"\" function that select al the rows that contain a keyword in a column and writes it to a file\"\"\"\n",
    "    sub = df[(df[column].str.contains(subject))]\n",
    "    file = subject + '.txt'\n",
    "    with open(file, 'w') as o:\n",
    "        for index, row in sub.iterrows():   \n",
    "            o.write(row[nr])\n",
    "            \n",
    "            \n",
    "# schrijf bijvoorbeeld alles over visie in meegeven column naar een bestand\n",
    "# write_subject_to_file(df_complete, 'visie', 'meegeven', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-surrey",
   "metadata": {},
   "source": [
    "# Analyse \n",
    "\n",
    "- 'indruk' #12\n",
    "- 'ontwikkelingen' #13\n",
    "- 'redenen' #14\n",
    "- 'meegeven #15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schrijf weg in tekst bestanden voor de summary\n",
    "df_complete = df_complete[df_complete.indruk.notnull()]\n",
    "\n",
    "with open('indruk_txt', 'w') as out:\n",
    "    for index, row in df_complete.iterrows():\n",
    "        out.write('\\n'+clean_line(row[12]))\n",
    "\n",
    "\n",
    "df_complete = df_complete[df_complete.ontwikkelingen.notnull()]\n",
    "\n",
    "with open('ontwikkelingen_txt', 'w') as out:\n",
    "    for index, row in df_complete.iterrows():\n",
    "        out.write('\\n'+clean_line(row[13]))\n",
    "\n",
    "\n",
    "df_complete = df_complete[df_complete.redenen.notnull()]\n",
    "\n",
    "with open('redenen_txt', 'w') as out:\n",
    "    for index, row in df_complete.iterrows():\n",
    "        out.write('\\n'+clean_line(row[14]))\n",
    "        \n",
    "\n",
    "df_complete = df_complete[df_complete.meegeven.notnull()]\n",
    "\n",
    "with open('meegeven_txt', 'w') as out:\n",
    "    for index, row in df_complete.iterrows():\n",
    "        out.write('\\n'+clean_line(row[15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-certificate",
   "metadata": {},
   "source": [
    "# Woord frequenties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the text, dit kan dus veranderd worden voor een andere tekst\n",
    "file = open('meegeven_txt', \"r\")\n",
    "text = \"\".join(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag the words\n",
    "doc = nlp(text.lower(), disable = ['ner', 'parser'])\n",
    "spacy_pos_tagged = [(word, word.tag_, word.pos_) for word in doc]\n",
    "df = pd.DataFrame(spacy_pos_tagged, columns=['word', 'pos_tag', 'tag_type'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the types\n",
    "print(set(df['tag_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select certain types\n",
    "advs = df.loc[((df['pos_tag'] == 'BW') & (df['tag_type'] == 'ADV'))]\n",
    "vreemd = df[df['tag_type'] == 'X']\n",
    "nouns = df[df.tag_type == 'NOUN']\n",
    "verbs = df[df.tag_type == 'VERB']\n",
    "intjs = df[df.tag_type == 'INTJ']\n",
    "props = df[df.tag_type == 'PROPN']\n",
    "adj = df[df.tag_type == 'ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create wordlists with selected types \n",
    "sub = pd.concat([nouns, vreemd])\n",
    "words = sub.word.astype(str).tolist()\n",
    "words = [word for word in words if word not in stopwords_dutch]\n",
    "#words = [stemmer.stem(word) for word in words]\n",
    "#words = [edit_distance(word, wordlist = DUTCH) for word in words if word not in DUTCH] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create frequencies\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-assault",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fdist.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-scheme",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check words\n",
    "fdist['gelijkwaardigheid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-torture",
   "metadata": {},
   "source": [
    "# Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make wordcloud\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib notebook\n",
    "def show_wordcloud(dictionary):\n",
    "    wc = WordCloud(background_color=\"white\",\n",
    "                   width=1000,height=1000,\n",
    "                   min_word_length=3,\n",
    "                   include_numbers=False,\n",
    "                   colormap = 'tab20',\n",
    "                   collocations=True,\n",
    "                   normalize_plurals=False).generate_from_frequencies(dictionary)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(wc)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "show_wordcloud(fdist)\n",
    "plt.savefig('wordcloud.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biza",
   "language": "python",
   "name": "biza"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
